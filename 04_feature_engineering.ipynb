{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS18 ML Essentials project\n",
    "# Module 4: Feature Engineering\n",
    "\n",
    "# Submitted by: Tzvi Eliezer Nir\n",
    "# mail: tzvienir@gmail.com\n",
    "# First submission: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook\n",
    "\n",
    "We will apply multiple feature enrichment methods on our data:\n",
    "* Feature **Extraction**: creating new features from existing ones:\n",
    "  * `track_album_release_date` can be split into Year, Month, Day, and in our case **Decade** might also be valuable.\n",
    "  * Years since release\n",
    "  * `language` - get the language based on the track name / lyrics - can be narrowed to English / Not-English\n",
    "* Feature Engineering: Converting data into a format suitable for modeling:\n",
    "  * find five-to-ten popular words in the `track_name` and create *dummy* column for if the song name include the words\n",
    "  * Sentiment Analysis of the song name  \n",
    "  * Sentiment Analysis of song lyrics\n",
    "  * Aggregating `track_artist` by Country/Continent (depends on category size)\n",
    "  * Aggregating `track_artist` by [Male, Female, Band]\n",
    "  * Artist Followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_pickle(\"./pickle/03_data_cleansing/data_cleansing.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `track_album_release_date` feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>track_popularity</th>\n",
       "      <th>track_album_id</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>...</th>\n",
       "      <th>edm</th>\n",
       "      <th>latin</th>\n",
       "      <th>pop</th>\n",
       "      <th>r&amp;b</th>\n",
       "      <th>rap</th>\n",
       "      <th>rock</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0017A6SJgTbfQVU2EtsPNo</td>\n",
       "      <td>Barbie's Cradle</td>\n",
       "      <td>41</td>\n",
       "      <td>1srJQ0njEQgd8w4XSqI4JQ</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.401</td>\n",
       "      <td>2</td>\n",
       "      <td>-10.068</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002xjHwzEx66OWFV2IP9dk</td>\n",
       "      <td>RIKA</td>\n",
       "      <td>15</td>\n",
       "      <td>1ficfUnZMaY1QkNp15Slzm</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.704</td>\n",
       "      <td>5</td>\n",
       "      <td>-6.242</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004s3t0ONYlzxII9PLgU6z</td>\n",
       "      <td>Steady Rollin</td>\n",
       "      <td>28</td>\n",
       "      <td>3z04Lb9Dsilqw68SHt6jLB</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.880</td>\n",
       "      <td>9</td>\n",
       "      <td>-4.739</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>008MceT31RotUANsKuzy3L</td>\n",
       "      <td>The.madpix.project</td>\n",
       "      <td>24</td>\n",
       "      <td>1Z4ANBVuhTlS6DprlP0m1q</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.794</td>\n",
       "      <td>10</td>\n",
       "      <td>-5.644</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>008rk8F6ZxspZT4bUlkIQG</td>\n",
       "      <td>YOSA &amp; TAAR</td>\n",
       "      <td>38</td>\n",
       "      <td>2BuYm9UcKvI0ydXs5JKwt0</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.838</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0499</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id        track_artist  track_popularity  \\\n",
       "0  0017A6SJgTbfQVU2EtsPNo     Barbie's Cradle                41   \n",
       "1  002xjHwzEx66OWFV2IP9dk                RIKA                15   \n",
       "2  004s3t0ONYlzxII9PLgU6z       Steady Rollin                28   \n",
       "3  008MceT31RotUANsKuzy3L  The.madpix.project                24   \n",
       "4  008rk8F6ZxspZT4bUlkIQG         YOSA & TAAR                38   \n",
       "\n",
       "           track_album_id  danceability  energy  key  loudness  mode  \\\n",
       "0  1srJQ0njEQgd8w4XSqI4JQ         0.682   0.401    2   -10.068     1   \n",
       "1  1ficfUnZMaY1QkNp15Slzm         0.582   0.704    5    -6.242     1   \n",
       "2  3z04Lb9Dsilqw68SHt6jLB         0.303   0.880    9    -4.739     1   \n",
       "3  1Z4ANBVuhTlS6DprlP0m1q         0.659   0.794   10    -5.644     0   \n",
       "4  2BuYm9UcKvI0ydXs5JKwt0         0.662   0.838    1    -6.300     1   \n",
       "\n",
       "   speechiness  ...  edm  latin  pop  r&b  rap  rock  year  month  day  decade  \n",
       "0       0.0236  ...    0      0    0    0    0     1  2001      1    1    2000  \n",
       "1       0.0347  ...    0      0    0    1    0     0  2018      1   26    2010  \n",
       "2       0.0442  ...    0      0    0    0    0     1  2017     11   21    2010  \n",
       "3       0.0540  ...    1      0    1    0    0     0  2015      8    7    2010  \n",
       "4       0.0499  ...    0      0    1    0    0     0  2018     11   16    2010  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract year, month, and day from track_album_release_date\n",
    "df['year'] = df['track_album_release_date'].dt.year\n",
    "df['month'] = df['track_album_release_date'].dt.month\n",
    "df['day'] = df['track_album_release_date'].dt.day\n",
    "\n",
    "# Calculate the decade\n",
    "df['decade'] = (df['year'] // 10) * 10\n",
    "\n",
    "# drop the track_album_release_date column\n",
    "df = df.drop('track_album_release_date', axis=1)\n",
    "\n",
    "# Display the updated dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              track_name language\n",
      "0              Despacito       es\n",
      "1           Shape of You       en\n",
      "2          Gangnam Style       tl\n",
      "3                Bonjour       fr\n",
      "4  Liebe ist für alle da       de\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "# Ensure consistent results\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({'track_name': ['Despacito', 'Shape of You', 'Gangnam Style', 'Bonjour', 'Liebe ist für alle da']})\n",
    "\n",
    "# Function to detect language\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return 'unknown'\n",
    "\n",
    "# Apply language detection\n",
    "df['language'] = df['track_name'].apply(detect_language)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langid\n",
      "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/heaphopper/anaconda3/lib/python3.12/site-packages (from langid) (1.26.4)\n",
      "Building wheels for collected packages: langid\n",
      "  Building wheel for langid (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941171 sha256=8846160acc62e90a924091a0632616daf488a140d705fbf9f564904f4077856f\n",
      "  Stored in directory: /home/heaphopper/.cache/pip/wheels/3c/bc/9d/266e27289b9019680d65d9b608c37bff1eff565b001c977ec5\n",
      "Successfully built langid\n",
      "Installing collected packages: langid\n",
      "Successfully installed langid-1.1.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              track_name language\n",
      "0              Despacito       en\n",
      "1           Shape of You       en\n",
      "2          Gangnam Style       en\n",
      "3                Bonjour       en\n",
      "4  Liebe ist für alle da       de\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import langid\n",
    "\n",
    "df = pd.DataFrame({'track_name': ['Despacito', 'Shape of You', 'Gangnam Style', 'Bonjour', 'Liebe ist für alle da']})\n",
    "\n",
    "df['language'] = df['track_name'].apply(lambda x: langid.classify(x)[0])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               track_name classification\n",
      "0               Despacito    Not English\n",
      "1            Shape of You        English\n",
      "2           Gangnam Style    Not English\n",
      "3                 Bonjour    Not English\n",
      "4   Liebe ist für alle da    Not English\n",
      "5       Bohemian Rhapsody    Not English\n",
      "6         Blinding Lights    Not English\n",
      "7          Hips Don’t Lie        English\n",
      "8                Senorita    Not English\n",
      "9                    Tusa    Not English\n",
      "10               Dynamite    Not English\n",
      "11            Savage Love    Not English\n",
      "12                  Creep    Not English\n",
      "13              Yesterday    Not English\n",
      "14  Un Homme et une Femme    Not English\n",
      "15       Ai Se Eu Te Pego    Not English\n",
      "16           Bésame Mucho    Not English\n",
      "17      Dragostea Din Tei    Not English\n",
      "18   Владимирский Централ    Not English\n",
      "19               Καλημέρα    Not English\n",
      "20                     東京    Not English\n",
      "21                     你好    Not English\n",
      "22                  ありがとう    Not English\n",
      "23                밤하늘의 별을    Not English\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "# Ensure consistent results\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Sample DataFrame with more songs\n",
    "df = pd.DataFrame({\n",
    "    'track_name': [\n",
    "        'Despacito', 'Shape of You', 'Gangnam Style', 'Bonjour', \n",
    "        'Liebe ist für alle da', 'Bohemian Rhapsody', 'Blinding Lights', \n",
    "        'Hips Don’t Lie', 'Senorita', 'Tusa', 'Dynamite', 'Savage Love', \n",
    "        'Creep', 'Yesterday', 'Un Homme et une Femme', 'Ai Se Eu Te Pego', \n",
    "        'Bésame Mucho', 'Dragostea Din Tei', 'Владимирский Централ', \n",
    "        'Καλημέρα', '東京', '你好', 'ありがとう', '밤하늘의 별을'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Function to classify as English / Not English\n",
    "def classify_english(text):\n",
    "    try:\n",
    "        return \"English\" if detect(text) == \"en\" else \"Not English\"\n",
    "    except LangDetectException:\n",
    "        return \"Not English\"\n",
    "\n",
    "# Apply classification\n",
    "df['classification'] = df['track_name'].apply(classify_english)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               track_name classification\n",
      "0               Despacito    Not English\n",
      "1            Shape of You        English\n",
      "2           Gangnam Style    Not English\n",
      "3                 Bonjour    Not English\n",
      "4   Liebe ist für alle da    Not English\n",
      "5       Bohemian Rhapsody    Not English\n",
      "6         Blinding Lights        English\n",
      "7          Hips Don’t Lie        English\n",
      "8                Senorita    Not English\n",
      "9                    Tusa    Not English\n",
      "10               Dynamite    Not English\n",
      "11            Savage Love    Not English\n",
      "12                  Creep        English\n",
      "13              Yesterday    Not English\n",
      "14  Un Homme et une Femme    Not English\n",
      "15       Ai Se Eu Te Pego    Not English\n",
      "16           Bésame Mucho    Not English\n",
      "17      Dragostea Din Tei    Not English\n",
      "18   Владимирский Централ    Not English\n",
      "19               Καλημέρα    Not English\n",
      "20                     東京    Not English\n",
      "21                     你好    Not English\n",
      "22                  ありがとう    Not English\n",
      "23                밤하늘의 별을    Not English\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect, detect_langs, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "# Ensure consistent results\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Sample DataFrame with more songs\n",
    "df = pd.DataFrame({\n",
    "    'track_name': [\n",
    "        'Despacito', 'Shape of You', 'Gangnam Style', 'Bonjour', \n",
    "        'Liebe ist für alle da', 'Bohemian Rhapsody', 'Blinding Lights', \n",
    "        'Hips Don’t Lie', 'Senorita', 'Tusa', 'Dynamite', 'Savage Love', \n",
    "        'Creep', 'Yesterday', 'Un Homme et une Femme', 'Ai Se Eu Te Pego', \n",
    "        'Bésame Mucho', 'Dragostea Din Tei', 'Владимирский Централ', \n",
    "        'Καλημέρα', '東京', '你好', 'ありがとう', '밤하늘의 별을'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Function to classify English / Not English with better accuracy\n",
    "def classify_english(text):\n",
    "    try:\n",
    "        # Detect language probabilities\n",
    "        langs = detect_langs(text)\n",
    "        \n",
    "        # If English is detected with high confidence, mark as English\n",
    "        for lang in langs:\n",
    "            if lang.lang == \"en\" and lang.prob > 0.4:  # Adjust threshold if needed\n",
    "                return \"English\"\n",
    "        \n",
    "        return \"Not English\"\n",
    "    \n",
    "    except LangDetectException:\n",
    "        return \"Not English\"\n",
    "\n",
    "# Apply classification\n",
    "df['classification'] = df['track_name'].apply(classify_english)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               track_name classification\n",
      "0               Despacito    Not English\n",
      "1            Shape of You        English\n",
      "2           Gangnam Style    Not English\n",
      "3                 Bonjour    Not English\n",
      "4   Liebe ist für alle da    Not English\n",
      "5       Bohemian Rhapsody    Not English\n",
      "6         Blinding Lights    Not English\n",
      "7          Hips Don’t Lie        English\n",
      "8                Senorita    Not English\n",
      "9                    Tusa    Not English\n",
      "10               Dynamite    Not English\n",
      "11            Savage Love    Not English\n",
      "12                  Creep    Not English\n",
      "13              Yesterday    Not English\n",
      "14  Un Homme et une Femme    Not English\n",
      "15       Ai Se Eu Te Pego    Not English\n",
      "16           Bésame Mucho    Not English\n",
      "17      Dragostea Din Tei    Not English\n",
      "18   Владимирский Централ    Not English\n",
      "19               Καλημέρα    Not English\n",
      "20                     東京    Not English\n",
      "21                     你好    Not English\n",
      "22                  ありがとう    Not English\n",
      "23                밤하늘의 별을    Not English\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "from collections import Counter\n",
    "\n",
    "# Ensure consistent results\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Sample DataFrame with more songs\n",
    "df = pd.DataFrame({\n",
    "    'track_name': [\n",
    "        'Despacito', 'Shape of You', 'Gangnam Style', 'Bonjour', \n",
    "        'Liebe ist für alle da', 'Bohemian Rhapsody', 'Blinding Lights', \n",
    "        'Hips Don’t Lie', 'Senorita', 'Tusa', 'Dynamite', 'Savage Love', \n",
    "        'Creep', 'Yesterday', 'Un Homme et une Femme', 'Ai Se Eu Te Pego', \n",
    "        'Bésame Mucho', 'Dragostea Din Tei', 'Владимирский Централ', \n",
    "        'Καλημέρα', '東京', '你好', 'ありがとう', '밤하늘의 별을'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Function to improve accuracy\n",
    "def detect_language(text, n_attempts=3):\n",
    "    try:\n",
    "        # Run detection multiple times and take the most common result\n",
    "        languages = [detect(text) for _ in range(n_attempts)]\n",
    "        most_common_lang = Counter(languages).most_common(1)[0][0]\n",
    "        return most_common_lang\n",
    "    except LangDetectException:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Function to classify English vs Not English\n",
    "def classify_english(text):\n",
    "    lang = detect_language(text)\n",
    "    return \"English\" if lang == \"en\" else \"Not English\"\n",
    "\n",
    "# Apply classification\n",
    "df['classification'] = df['track_name'].apply(classify_english)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lyricsgenius in /home/heaphopper/anaconda3/lib/python3.12/site-packages (3.3.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.6.0 in /home/heaphopper/anaconda3/lib/python3.12/site-packages (from lyricsgenius) (4.12.3)\n",
      "Requirement already satisfied: requests>=2.20.0 in /home/heaphopper/anaconda3/lib/python3.12/site-packages (from lyricsgenius) (2.32.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/heaphopper/anaconda3/lib/python3.12/site-packages (from beautifulsoup4>=4.6.0->lyricsgenius) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/heaphopper/anaconda3/lib/python3.12/site-packages (from requests>=2.20.0->lyricsgenius) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/heaphopper/anaconda3/lib/python3.12/site-packages (from requests>=2.20.0->lyricsgenius) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/heaphopper/anaconda3/lib/python3.12/site-packages (from requests>=2.20.0->lyricsgenius) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/heaphopper/anaconda3/lib/python3.12/site-packages (from requests>=2.20.0->lyricsgenius) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lyricsgenius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'token' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlyricsgenius\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Genius\n\u001b[0;32m----> 3\u001b[0m genius \u001b[38;5;241m=\u001b[39m Genius(token)\n\u001b[1;32m      4\u001b[0m genius\u001b[38;5;241m.\u001b[39msearch_artist(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAndy Shauf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m artist\u001b[38;5;241m.\u001b[39msave_lyrics()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'token' is not defined"
     ]
    }
   ],
   "source": [
    "from lyricsgenius import Genius\n",
    "\n",
    "genius = Genius(token)\n",
    "genius.search_artist('Andy Shauf')\n",
    "artist.save_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lyrics': \"Turn your magic on, Umi she'd say\\r\\nEverything you want's a dream away\\r\\nWe are legends, every day\\r\\nThat's what she told me\\r\\nTurn your magic on, to me she'd say\\n\\nEverything you want's a dream away\\n\\nUnder this pressure, under this weight\\n\\nWe are diamonds \\n\\n\\n\\nI feel my heart beating\\n\\nI feel my heart underneath my skin\\n\\nI feel my heart beating\\n\\nOh, you make me feel\\n\\nLike I'm alive again\\n\\n\\n\\nAlive again!\\n\\n\\n\\nOh, you make me feel\\n\\nLike I'm alive again\\n\\n\\n\\nSaid I can't go on, not in this way\\n\\nI'm a dream that died by light of day\\n\\nGonna hold up half the sky and say\\n\\nOnly I own me\\n\\n\\n\\nI feel my heart beating\\n\\nI feel my heart underneath my skin\\n\\nOh, I can feel my heart beating\\n\\n'Cause you make me feel\\n\\nLike I'm alive again\\n\\n\\n\\nAlive again!\\n\\n\\n\\nOh, you make me feel\\n\\nLike I'm alive again\\n\\n\\n\\nTurn your magic on, Umi she'd say\\n\\nEverything you want's a dream away\\n\\nUnder this pressure, under this weight\\n\\nWe are diamonds taking shape\\n\\nWe are diamonds taking shape\\n\\n\\n\\n(Woo, woo)\\n\\n\\n\\nIf we've only got this life\\n\\nThis adventure, oh then I\\n\\nAnd if we've only got this life\\n\\nYou'll get me through alive\\n\\nAnd if we've only got this life\\n\\nIn this adventure, oh then I\\n\\nWanna share it with you\\n\\nWith you, with you\\n\\nI said, oh, say oh\\n\\n\\n\\n(Woo hoo, woo hoo...)\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.lyrics.ovh/v1/Coldplay/Adventure of a Lifetime\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(data)\n",
    "else:\n",
    "    print(f\"Failed to retrieve data: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.read_pickle(\"./pickle/01_data_preparation/df_text.pkl\")\n",
    "df_text = df_text.drop(columns=['playlist_name'])\n",
    "df_text = df_text.merge(df[['track_id', 'track_artist']], on='track_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df_text.drop(columns=['playlist_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df_text.drop_duplicates(subset='track_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df_text.merge(df[['track_id', 'track_artist']], on='track_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_album_name</th>\n",
       "      <th>track_artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28356</td>\n",
       "      <td>28352</td>\n",
       "      <td>28352</td>\n",
       "      <td>28352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>28356</td>\n",
       "      <td>23449</td>\n",
       "      <td>19743</td>\n",
       "      <td>10692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>6f807x0ima9a1j3VPbc7VN</td>\n",
       "      <td>Breathe</td>\n",
       "      <td>Greatest Hits</td>\n",
       "      <td>Queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>135</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      track_id track_name track_album_name track_artist\n",
       "count                    28356      28352            28352        28352\n",
       "unique                   28356      23449            19743        10692\n",
       "top     6f807x0ima9a1j3VPbc7VN    Breathe    Greatest Hits        Queen\n",
       "freq                         1         18              135          130"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics(row):\n",
    "    artist = row['track_artist']\n",
    "    title = row['track_name']\n",
    "    url = f\"https://api.lyrics.ovh/v1/{artist}/{title}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        data['lyrics'] = data['lyrics'].replace('\\r\\n', ' ')\n",
    "        return data['lyrics']\n",
    "    else:\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_text.sample(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['lyrics'] = df_sample.apply(get_lyrics, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_album_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1000</td>\n",
       "      <td>989</td>\n",
       "      <td>966</td>\n",
       "      <td>891</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>7cG5fCOSThJTaKxDHoRT0s</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Greatest Hits</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>[Instrumental]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      track_id track_name track_album_name track_artist  \\\n",
       "count                     1000       1000             1000         1000   \n",
       "unique                    1000        989              966          891   \n",
       "top     7cG5fCOSThJTaKxDHoRT0s       Easy    Greatest Hits     J Balvin   \n",
       "freq                         1          3                8            5   \n",
       "\n",
       "                lyrics  \n",
       "count              435  \n",
       "unique             431  \n",
       "top     [Instrumental]  \n",
       "freq                 3  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text['lyrics'] = df_text.apply(get_lyrics, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_pickle(\"./pickle/04_feature_engineering/df_sample.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "from collections import Counter\n",
    "\n",
    "# Function to improve accuracy\n",
    "def detect_language(text, n_attempts=3):\n",
    "    try:\n",
    "        # Run detection multiple times and take the most common result\n",
    "        languages = [detect(text) for _ in range(n_attempts)]\n",
    "        most_common_lang = Counter(languages).most_common(1)[0][0]\n",
    "        return most_common_lang\n",
    "    except LangDetectException:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Function to classify English vs Not English\n",
    "def classify_english(text):\n",
    "    lang = detect_language(text)\n",
    "    return \"English\" if lang == \"en\" else \"Not English\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_album_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12130</th>\n",
       "      <td>7cG5fCOSThJTaKxDHoRT0s</td>\n",
       "      <td>Going Back To Memphis - Remastered</td>\n",
       "      <td>Capitol Rarities 1968-1977 (Remastered)</td>\n",
       "      <td>The Band</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>70vvnTUamBXOc0vRk7BBDu</td>\n",
       "      <td>Poker Face</td>\n",
       "      <td>The Fame Monster (International Deluxe)</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>I wanna hold em' like they do in Texas Plays. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>5mIM8wMyZ8NqhNP3brwnEV</td>\n",
       "      <td>Get Away</td>\n",
       "      <td>Escape</td>\n",
       "      <td>Paperwhite</td>\n",
       "      <td>Make me an offer One heart for true love Cards...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>5801f9g6Kb8D4qNjXWBusY</td>\n",
       "      <td>Legend of the South</td>\n",
       "      <td>Creeker 2</td>\n",
       "      <td>Upchurch</td>\n",
       "      <td>There's a warm wind ablowin' And a burnin' sun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25438</th>\n",
       "      <td>3AuvTRlw1TQulraCRTZnKc</td>\n",
       "      <td>Together</td>\n",
       "      <td>Together</td>\n",
       "      <td>Vinsand</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>1MijKOgtIl3uK70qYrZnoy</td>\n",
       "      <td>Sad Songs In The Summer</td>\n",
       "      <td>It Was A Sad Fucking Summer</td>\n",
       "      <td>Olivia O'Brien</td>\n",
       "      <td>Sad songs in the summer Heartbreak till the da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>3QEWSE2yXJN85Q66gxY64O</td>\n",
       "      <td>Takeoff</td>\n",
       "      <td>Takeoff</td>\n",
       "      <td>High John</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>53HUxlAstNtpgKVU6VV2JL</td>\n",
       "      <td>American Spirit</td>\n",
       "      <td>happysad</td>\n",
       "      <td>Meg &amp; Dia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6588</th>\n",
       "      <td>5UQOmTylBEdsIfSn37v3DO</td>\n",
       "      <td>Straight Up Menace</td>\n",
       "      <td>The Best of MC Eiht</td>\n",
       "      <td>MC Eiht</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9039</th>\n",
       "      <td>2CPturRUlpvirYr7VpkXCV</td>\n",
       "      <td>It Ain't Hard to Tell</td>\n",
       "      <td>Illmatic</td>\n",
       "      <td>Nas</td>\n",
       "      <td>It ain't hard to tell, I excel, then prevail T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     track_id                          track_name  \\\n",
       "12130  7cG5fCOSThJTaKxDHoRT0s  Going Back To Memphis - Remastered   \n",
       "2058   70vvnTUamBXOc0vRk7BBDu                          Poker Face   \n",
       "4962   5mIM8wMyZ8NqhNP3brwnEV                            Get Away   \n",
       "7996   5801f9g6Kb8D4qNjXWBusY                 Legend of the South   \n",
       "25438  3AuvTRlw1TQulraCRTZnKc                            Together   \n",
       "...                       ...                                 ...   \n",
       "1971   1MijKOgtIl3uK70qYrZnoy             Sad Songs In The Summer   \n",
       "5272   3QEWSE2yXJN85Q66gxY64O                             Takeoff   \n",
       "1922   53HUxlAstNtpgKVU6VV2JL                     American Spirit   \n",
       "6588   5UQOmTylBEdsIfSn37v3DO                  Straight Up Menace   \n",
       "9039   2CPturRUlpvirYr7VpkXCV               It Ain't Hard to Tell   \n",
       "\n",
       "                              track_album_name    track_artist  \\\n",
       "12130  Capitol Rarities 1968-1977 (Remastered)        The Band   \n",
       "2058   The Fame Monster (International Deluxe)       Lady Gaga   \n",
       "4962                                    Escape      Paperwhite   \n",
       "7996                                 Creeker 2        Upchurch   \n",
       "25438                                 Together         Vinsand   \n",
       "...                                        ...             ...   \n",
       "1971               It Was A Sad Fucking Summer  Olivia O'Brien   \n",
       "5272                                   Takeoff       High John   \n",
       "1922                                  happysad       Meg & Dia   \n",
       "6588                       The Best of MC Eiht         MC Eiht   \n",
       "9039                                  Illmatic             Nas   \n",
       "\n",
       "                                                  lyrics  \n",
       "12130                                               None  \n",
       "2058   I wanna hold em' like they do in Texas Plays. ...  \n",
       "4962   Make me an offer One heart for true love Cards...  \n",
       "7996   There's a warm wind ablowin' And a burnin' sun...  \n",
       "25438                                               None  \n",
       "...                                                  ...  \n",
       "1971   Sad songs in the summer Heartbreak till the da...  \n",
       "5272                                                None  \n",
       "1922                                                None  \n",
       "6588                                                None  \n",
       "9039   It ain't hard to tell, I excel, then prevail T...  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Apply classification\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlyrics\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(classify_english)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[68], line 18\u001b[0m, in \u001b[0;36mclassify_english\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify_english\u001b[39m(text):\n\u001b[0;32m---> 18\u001b[0m     lang \u001b[38;5;241m=\u001b[39m detect_language(text)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnglish\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot English\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[68], line 10\u001b[0m, in \u001b[0;36mdetect_language\u001b[0;34m(text, n_attempts)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_language\u001b[39m(text, n_attempts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;66;03m# Run detection multiple times and take the most common result\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m         languages \u001b[38;5;241m=\u001b[39m [detect(text) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_attempts)]\n\u001b[1;32m     11\u001b[0m         most_common_lang \u001b[38;5;241m=\u001b[39m Counter(languages)\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m most_common_lang\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langdetect/detector_factory.py:129\u001b[0m, in \u001b[0;36mdetect\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    127\u001b[0m init_factory()\n\u001b[1;32m    128\u001b[0m detector \u001b[38;5;241m=\u001b[39m _factory\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[0;32m--> 129\u001b[0m detector\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m detector\u001b[38;5;241m.\u001b[39mdetect()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langdetect/detector.py:104\u001b[0m, in \u001b[0;36mDetector.append\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mappend\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Append the target text for language detection.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    If the total size of target text exceeds the limit size specified by\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    Detector.set_max_text_length(int), the rest is cut down.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mURL_RE\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[1;32m    105\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMAIL_RE\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[1;32m    106\u001b[0m     text \u001b[38;5;241m=\u001b[39m NGram\u001b[38;5;241m.\u001b[39mnormalize_vi(text)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object, got 'NoneType'"
     ]
    }
   ],
   "source": [
    "# Apply classification\n",
    "df_sample['classification'] = df_sample['lyrics'].apply(classify_english)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
